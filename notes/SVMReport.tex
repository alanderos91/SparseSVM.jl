\documentclass[11pt]{article}
\usepackage{amsbsy,amsthm,amsmath,amssymb}
\usepackage{booktabs}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{example}{Example}[section]
\newcommand{\svskip}{\vspace{1.75mm}}
\newcommand{\mvskip}{\vspace{.25in}}
\newcommand{\lvskip}{\vspace{.5in}}
\def\E{\mathop{\rm E\,\!}\nolimits}
\def\Var{\mathop{\rm Var}\nolimits}
\def\Cov{\mathop{\rm Cov}\nolimits}
\def\den{\mathop{\rm den}\nolimits}
\def\midd{\mathop{\,|\,}\nolimits}
\def\sgn{\mathop{\rm sgn}\nolimits}
\def\vec{\mathop{\rm vec}\nolimits}
\def\sinc{\mathop{\rm sinc}\nolimits}
\def\curl{\mathop{\rm curl}\nolimits}
\def\div{\mathop{\rm div}\nolimits}
\def\tr{\mathop{\rm tr}\nolimits}
\def\len{\mathop{\rm len}\nolimits}
\def\diag{\mathop{diag}\nolimits}
\def\dist{\mathop{\rm dist}\nolimits}
\def\cond{\mathop{\rm cond}\nolimits}
\def\prox{\mathop{\rm prox}\nolimits}
\def\argmin{\mathop{\rm argmin}\nolimits}
\def\amp{\mathop{\;\:}\nolimits}
\newcommand{\bzero}{\boldsymbol{0}}
\newcommand{\bone}{\boldsymbol{1}}
\newcommand{\ba}{\boldsymbol{a}}
\newcommand{\bb}{\boldsymbol{b}}
\newcommand{\bc}{\boldsymbol{c}}
\newcommand{\bd}{\boldsymbol{d}}
\newcommand{\be}{\boldsymbol{e}}
\newcommand{\fb}{\boldsymbol{f}}
\newcommand{\bg}{\boldsymbol{g}}
\newcommand{\bh}{\boldsymbol{h}}
\newcommand{\bi}{\boldsymbol{i}}
\newcommand{\bj}{\boldsymbol{j}}
\newcommand{\bk}{\boldsymbol{k}}
\newcommand{\bl}{\boldsymbol{l}}
\newcommand{\bm}{\boldsymbol{m}}
\newcommand{\bn}{\boldsymbol{n}}
\newcommand{\bo}{\boldsymbol{o}}
\newcommand{\bp}{\boldsymbol{p}}
\newcommand{\bq}{\boldsymbol{q}}
\newcommand{\br}{\boldsymbol{r}}
\newcommand{\bs}{\boldsymbol{s}}
\newcommand{\bt}{\boldsymbol{t}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\bA}{\boldsymbol{A}}
\newcommand{\bB}{\boldsymbol{B}}
\newcommand{\bC}{\boldsymbol{C}}
\newcommand{\bD}{\boldsymbol{D}}
\newcommand{\bE}{\boldsymbol{E}}
\newcommand{\bF}{\boldsymbol{F}}
\newcommand{\bG}{\boldsymbol{G}}
\newcommand{\bH}{\boldsymbol{H}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\bJ}{\boldsymbol{J}}
\newcommand{\bK}{\boldsymbol{K}}
\newcommand{\bL}{\boldsymbol{L}}
\newcommand{\bM}{\boldsymbol{M}}
\newcommand{\bN}{\boldsymbol{N}}
\newcommand{\bO}{\boldsymbol{O}}
\newcommand{\bP}{\boldsymbol{P}}
\newcommand{\bQ}{\boldsymbol{Q}}
\newcommand{\bR}{\boldsymbol{R}}
\newcommand{\bS}{\boldsymbol{S}}
\newcommand{\bT}{\boldsymbol{T}}
\newcommand{\bU}{\boldsymbol{U}}
\newcommand{\bV}{\boldsymbol{V}}
\newcommand{\bW}{\boldsymbol{W}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bY}{\boldsymbol{Y}}
\newcommand{\bZ}{\boldsymbol{Z}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bnu}{\boldsymbol{\nu}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bpi}{\boldsymbol{\pi}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bomega}{\boldsymbol{\omega}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bLambda}{\boldsymbol{\Lambda}}
\newcommand{\bXi}{\boldsymbol{\Xi}}
\newcommand{\bPi}{\boldsymbol{\Pi}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bUpsilon}{\boldsymbol{\Upsilon}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bPsi}{\boldsymbol{\Psi}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}


\begin{document}

\section*{\center Sparse SVMs via Distance Penalization}

In these notes we consider applications of distance to set penalties in training support vector machines for classification tasks.
Specifically, we augment the squared hinge-loss model, $L(\bbeta)=\sum_{i=1}^m \max\{1-y_i \bx_i^t\bbeta,0\}^2$, by the distance penalty $\dist(\bbeta, S_{c})^{2}$ where $S_{c}$ is the set of vectors with $c$ non-zero components.
We assume here that the last entry $\beta_p$ of $\bbeta$ is the intercept and the last entry $x_{ip}$ of each $\bx_i$ is accordingly $1$.
Several algorithms are possible for minimizing $L(\bbeta)$.
In MM optimization, the squared hinge function $\max\{1-u,0\}^2$ is majorized by $(u_k-u)^2$ for $u_k \ge 1$ and by $(1-u)^2$ for $u_k < 1$.
Hence, the loss is majorized by
\begin{eqnarray*}
L(\bbeta) & \le & \sum_{i=1}^m
\begin{cases} (1-y_i \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k \le 1 \\
(y_i \bx_i\bbeta_k - y_i \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k > 1 .\end{cases}
\end{eqnarray*} 
The sparsity penalty is majorized by $\rho \|\bbeta-P_{S_{c}}(\bbeta_k)\|^2$, where $P_{S}$ denotes projection onto $S$. It follows that minimization of the surrogate reduces to iteratively re-weighted least squares (IRWLS). When $y_i \in \{-1,1\}$, the surrogate becomes
\begin{eqnarray*}
L(\bbeta) & \le & \sum_{i=1}^m
\begin{cases} (y_i - \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k \le 1 \\
(\bx_i^t \bbeta_k - \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k > 1 . \end{cases}
\end{eqnarray*}
If $\bX$ is the matrix with $i$th row $\bx_i^t$ and $\by$ is the vector with $i$th component $y_i$, then the surrogate can be expressed as
\begin{eqnarray*}
g_{\rho}(\bbeta \mid \bbeta_{k})
=
\left\|\begin{pmatrix}\bz_k \\\bp_{k} \end{pmatrix}-
\begin{pmatrix} \bX \\ \bD_{\rho}\end{pmatrix}\bbeta
\right\|^2,
\end{eqnarray*}
where $\bz_k$ has $i$th component $y_i$ when $y_i \bx_i^t\bbeta_k \le 1$
and $\bx_i^t\bbeta_k$ otherwise. 
This formulation of the problem connects two important cases.
A ridge penalty version requires setting $\bp_{k} = \bzero$ and $\bD_{\rho} = \begin{pmatrix} \sqrt{\rho} \bI & \bzero_{p-1} \\ \bzero_{p-1}^{t} & 0 \end{pmatrix}$.
For sparse estimation we set $\bp_k = \sqrt{\rho} P_{S_{c}}(\bbeta_k)$ and $\bD_{\rho} = \sqrt{\rho} \bI$.
The advantage of the latter is that it induces a target sparsity level $c$ directly via projection at the expense of convexity, whereas the former is a convex program but suffers from shrinkage.

Here we will focus on the sparse estimation problem based on projection and use the notation $g_{c,\rho}(\bbeta \mid \bbeta_{k})$ to emphasize hyperparameters.
Following the penalty method of optimization, our goal is to obtain $c$-sparse solutions by solving a sequence of subproblems.
Specifically, initialize $\rho_{0}$ and $\bbeta_{c,0}$.
We proceed as follows:
\begin{enumerate}
    \item Given $\rho_{l}$, obtain $\bbeta_{c,l+1} = \argmin_{\bbeta} L(\bbeta) + \rho_{l} \dist(\bbeta, S_{c})^{2}$ using the IRWLS surrogate and $\bbeta_{c,l}$ as a warm-start.
    \item Set $l \to l + 1$ and update $\rho_{l} \to \rho_{l+1}$.
\end{enumerate}
If the sequence $\{\rho_{l}\}$ is chosen appropriately, then $\bbeta_{c,l}$ converges to $\bbeta_{c}$ with negligible numerical instability.

\section*{\center Two Candidate MM Algorithms}
In this section we derive two algorithms using the IRWLS surrogate.

Naively, one may attempt to solve the normal equations directly and obtain an explicit update rule for $\bbeta_{k+1}$ based on the current iterate $\bbeta_{k}$.
The Hessian $\bX^{t} \bX + \rho \bI$ is likely to have poor numerical properties, especially in high dimensional problems, which thwart any line of attack based on iterative methods like LSMR.
Furthermore, one cannot rely on caching a factorization of the Hessian because it depends on a changing penalty coefficient $\rho$.

Alternatively, if $\bX$ has singular value decomposition $\bU \bS \bV^{t}$ then the normal equations reduce to
\begin{equation}
\label{alg:MM}
\begin{aligned}
    (\bV \bS^{2} \bV^{t} + \rho \bI) \bbeta &= \bX^{t} \bz_{k} + \rho \bp_{k} \\
    \implies \bbeta_{k+1} &= \bV \bD^{-1} \bS \bU^{t} \bz_{k}
    + \rho \bV \bD^{-1} \bV^{t} \bp_{k} \\
    \implies \bbeta_{k+1} &= \bM_{1} \bz_{k} + \bM_{2} \bp_{k}.
\end{aligned}
\end{equation}
where $\bD = (\bS^{2} + \rho \bI)$.
The matrices $\bM_{1}$ and $\bM_{2}$ may be cached once $\rho$ is changed.
This makes for a simple MM algorithm based on two GEMV operations per iteration.
Nesterov acceleration is a prerequisite for a fast proximal distance algorithm.

The method of steepest descent is also attractive.
The gradient for the IRWLS surrogate is the sum $-\sum_{i=1}^m 1_{\{1-y_i\bx_i^t\bbeta > 0\}}(1-y_i\bx_i^t\bbeta)y_i\bx_i$.
Because the surrogate is a quadratic, it is easy to compute an approximately optimal step size $\gamma_{k}$ for a given descent direction $\bq_{k} \equiv \nabla g_{\rho}(\bbeta_{k} \mid \bbeta_{k})$.
The steepest descent update is therefore
\begin{equation}
\label{alg:SD}
\begin{aligned}
    \gamma_{k} &= \argmin_{\gamma} g_{\rho}(\bbeta_{k} - \gamma \bq_{k})
    = \frac{\|\bq_{k}\|^{2}}{\|\bX \bq_{k}\|^{2} + \rho \|\bq_{k}\|^{2}}, \\
    \bbeta_{k+1} &= \bbeta_{k} - \gamma_{k} \bq_{k}.
\end{aligned}
\end{equation}
In practice, the denominator in the step size formula should be perturbed by a small number $\epsilon$ (such as the machine epsilon) to avoid the indeterminate form $0 / 0$.
Furthermore, step-halving should be used to guarantee decreasing the penalized objective.

\section*{\center Numerical Experiments}

Here we apply our MM algorithms to classification tasks on both synthetic and ``real world'' data.
The chosen data sets are as follows:
\begin{table}[!h]
    \centering
    \begin{tabular}{lllll}
        \toprule
        Name & Classes & No. Train & Features & No. Test \\
        \midrule
        \texttt{synthetic} & 2 & 1000 & 500 & 1000 \\
        \texttt{iris} & 3 & 120 & 4 & 30 \\
        \texttt{letter-recognition} & 26 & 16000 & 16 & 4000 \\
        \texttt{MNIST-digits} & 10 & 60000 & 784 & 10000 \\
        \bottomrule
    \end{tabular}
    \caption{Summary of data sets for experiments.}
\end{table}
Binary classification is straightforward using the decision rule $\bx \mapsto \sgn (\bx^t \bbeta$).
In the examples with multiple classes $N$, we train $\binom{N}{2}$ SVMs under the one-against-one paradigm.
If classes are labeled $\{1, 2, \ldots, N\}$ then the we take our decision rule to be the ``Max Vote'' classifier $\bx \mapsto \arg\max v_{j}(\bx)$ where $v_{j}(\bx)$ is the number of votes received for class $j$ from each of the $\binom{N}{2}$ SVMs based on the binary decision rule.

Here we refer to the algorithms implied by (\ref{alg:MM}) and (\ref{alg:SD}) as ``MM'' and ``SD'', respectively.
Method MM uses Nesterov acceleration, whereas SD only uses step-halving to avoid an increase in the objective.

\subsection*{Experiment 1: Sensitivity to Initial Conditions}

To check sensitivity to the initial guess, $\bbeta_{0}$, we solve each SVM problem with 100 replicates with each component of $\bbeta_{0}$ drawn from the standard normal distribution.
We report the total number of iterations, time, test accuracy, objective, and distance to the sparsity set for each dataset in Table \ref{tab:experiment1}.
Iteration counts, timings, objectives, and distances are summed over multiple SVMs in the case of multiple classes; for example, in an example with 10 classes we take the objective as $\sum_{j} \text{objective}(\text{SVM}~j)$ where the sum ranges over $\binom{10}{2}$ SVMs.
Values for objectives and distances are adjusted by number of samples and number of features, respectively, to account for problem size.
During training, each SVM (in both binary and multi-class cases) is alloted $10^{4}$ inner iterations to minimize the distance penalized objective for fixed $\rho$ up to a relative tolerance $\epsilon = 10^{-6}$.
The sparsity level is restricted to $c = \lceil 0.5 \times \text{features} \rceil$ across all examples.
We set $\rho_{0} = 1$ and send $\rho_{n}$ to $\infty$ by the update $\rho_{n+1} = 1.5 \rho_{n}$ over 50 outer iterations.
\begin{table}[!h]
    \centering
    \begin{scriptsize}
    \begin{tabular}{llllll}
        \toprule
        Name & Iter. & Time (s) & Acc. (\%) & Obj. & Dist. \\
        \midrule
        \texttt{synthetic} &&&&& \\
        \hphantom{ab} MM & 269 & 0.34 & 87.0 & $2.273 \times 10^{-7}$ & $1.4 \times 10^{-6}$ \\
        \hphantom{ab} SD & 4511 & 0.26 & 100.0 & $1.202 \times 10^{-6}$ & $5.3 \times 10^{-6}$ \\
        \texttt{iris} &&&&& \\
        \hphantom{ab} MM & 2440 & $2.0 \times 10^{-3}$ & 90.0 & 0.1990 & $3.7 \times 10^{-4}$ \\
        \hphantom{ab} SD & 7527 & $7.6 \times 10^{-3}$ & 90.0 & 0.2715 & $6.2 \times 10^{-4}$ \\
        \texttt{letter-recognition} &&&&& \\
        \hphantom{ab} MM & $1.5 \times 10^{6}$ & 10 & 78.0 & 67.07 & 1.0 \\
        \hphantom{ab} SD & $4.8 \times 10^{6}$ & 58 & 73.0 & 109.4 & 1.3 \\
        \texttt{MNIST-digits} &&&&& \\
        \hphantom{ab} MM & 8049 & 351 & 10.0 & 42.46 & 0.040 \\
        \hphantom{ab} SD & $1.4 \times 10^{5}$ & 898 & 11.0 & 42.48 & 0.042 \\
        \bottomrule
    \end{tabular}
    \end{scriptsize}
    \caption{
        \label{tab:experiment1}
        Results indicate median values aggregated from 100 replicates.
        }
\end{table}

\subsection*{Experiment 2: Sensitivity to Sparsity Level}

Vary sparsity level $s$ over some range.

\begin{table}[!h]
    \centering
    \begin{tabular}{lllll}
        \toprule
        Name & Time (s) & Iter & Train Acc. & Test Acc. \\
        \midrule
        \texttt{synthetic} & ??? & ??? & ??? & ??? \\
        \texttt{iris} & ??? & ??? & ??? & ??? \\
        \texttt{letter-recognition} & ??? & ??? & ??? & ??? \\
        \texttt{MNIST-digits} & ??? & ??? & ??? & ??? \\
        \bottomrule
    \end{tabular}
    \caption{To be implemented soon.}
\end{table}

\end{document}
