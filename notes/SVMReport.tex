\documentclass[11pt]{article}
\usepackage{amsbsy,amsthm,amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}

\graphicspath{{../experiments/}}

\newtheorem{proposition}{Proposition}[section]
\newtheorem{example}{Example}[section]
\newcommand{\svskip}{\vspace{1.75mm}}
\newcommand{\mvskip}{\vspace{.25in}}
\newcommand{\lvskip}{\vspace{.5in}}
\def\E{\mathop{\rm E\,\!}\nolimits}
\def\Var{\mathop{\rm Var}\nolimits}
\def\Cov{\mathop{\rm Cov}\nolimits}
\def\den{\mathop{\rm den}\nolimits}
\def\midd{\mathop{\,|\,}\nolimits}
\def\sgn{\mathop{\rm sgn}\nolimits}
\def\vec{\mathop{\rm vec}\nolimits}
\def\sinc{\mathop{\rm sinc}\nolimits}
\def\curl{\mathop{\rm curl}\nolimits}
\def\div{\mathop{\rm div}\nolimits}
\def\tr{\mathop{\rm tr}\nolimits}
\def\len{\mathop{\rm len}\nolimits}
\def\diag{\mathop{diag}\nolimits}
\def\dist{\mathop{\rm dist}\nolimits}
\def\cond{\mathop{\rm cond}\nolimits}
\def\prox{\mathop{\rm prox}\nolimits}
\def\argmin{\mathop{\rm argmin}\nolimits}
\def\amp{\mathop{\;\:}\nolimits}
\newcommand{\bzero}{\boldsymbol{0}}
\newcommand{\bone}{\boldsymbol{1}}
\newcommand{\ba}{\boldsymbol{a}}
\newcommand{\bb}{\boldsymbol{b}}
\newcommand{\bc}{\boldsymbol{c}}
\newcommand{\bd}{\boldsymbol{d}}
\newcommand{\be}{\boldsymbol{e}}
\newcommand{\fb}{\boldsymbol{f}}
\newcommand{\bg}{\boldsymbol{g}}
\newcommand{\bh}{\boldsymbol{h}}
\newcommand{\bi}{\boldsymbol{i}}
\newcommand{\bj}{\boldsymbol{j}}
\newcommand{\bk}{\boldsymbol{k}}
\newcommand{\bl}{\boldsymbol{l}}
\newcommand{\bm}{\boldsymbol{m}}
\newcommand{\bn}{\boldsymbol{n}}
\newcommand{\bo}{\boldsymbol{o}}
\newcommand{\bp}{\boldsymbol{p}}
\newcommand{\bq}{\boldsymbol{q}}
\newcommand{\br}{\boldsymbol{r}}
\newcommand{\bs}{\boldsymbol{s}}
\newcommand{\bt}{\boldsymbol{t}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\bA}{\boldsymbol{A}}
\newcommand{\bB}{\boldsymbol{B}}
\newcommand{\bC}{\boldsymbol{C}}
\newcommand{\bD}{\boldsymbol{D}}
\newcommand{\bE}{\boldsymbol{E}}
\newcommand{\bF}{\boldsymbol{F}}
\newcommand{\bG}{\boldsymbol{G}}
\newcommand{\bH}{\boldsymbol{H}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\bJ}{\boldsymbol{J}}
\newcommand{\bK}{\boldsymbol{K}}
\newcommand{\bL}{\boldsymbol{L}}
\newcommand{\bM}{\boldsymbol{M}}
\newcommand{\bN}{\boldsymbol{N}}
\newcommand{\bO}{\boldsymbol{O}}
\newcommand{\bP}{\boldsymbol{P}}
\newcommand{\bQ}{\boldsymbol{Q}}
\newcommand{\bR}{\boldsymbol{R}}
\newcommand{\bS}{\boldsymbol{S}}
\newcommand{\bT}{\boldsymbol{T}}
\newcommand{\bU}{\boldsymbol{U}}
\newcommand{\bV}{\boldsymbol{V}}
\newcommand{\bW}{\boldsymbol{W}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bY}{\boldsymbol{Y}}
\newcommand{\bZ}{\boldsymbol{Z}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bnu}{\boldsymbol{\nu}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bpi}{\boldsymbol{\pi}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bomega}{\boldsymbol{\omega}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bLambda}{\boldsymbol{\Lambda}}
\newcommand{\bXi}{\boldsymbol{\Xi}}
\newcommand{\bPi}{\boldsymbol{\Pi}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bUpsilon}{\boldsymbol{\Upsilon}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bPsi}{\boldsymbol{\Psi}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}


\begin{document}

\section*{\center Sparse SVMs via Distance Penalization}

In these notes we consider applications of distance to set penalties in training support vector machines for classification tasks.
Specifically, we augment the squared hinge-loss model, $L(\bbeta)=\sum_{i=1}^m \max\{1-y_i \bx_i^t\bbeta,0\}^2$, by the distance penalty $\dist(\bbeta, S_{c})^{2}$ where $S_{c}$ is the set of vectors with $c$ non-zero components.
We assume here that the last entry $\beta_p$ of $\bbeta$ is the intercept and the last entry $x_{ip}$ of each $\bx_i$ is accordingly $1$.
Several algorithms are possible for minimizing $L(\bbeta)$.
In MM optimization, the squared hinge function $\max\{1-u,0\}^2$ is majorized by $(u_k-u)^2$ for $u_k \ge 1$ and by $(1-u)^2$ for $u_k < 1$.
Hence, the loss is majorized by
\begin{eqnarray*}
L(\bbeta) & \le & \sum_{i=1}^m
\begin{cases} (1-y_i \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k \le 1 \\
(y_i \bx_i\bbeta_k - y_i \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k > 1 .\end{cases}
\end{eqnarray*} 
The sparsity penalty is majorized by $\rho \|\bbeta-P_{S_{c}}(\bbeta_k)\|^2$, where $P_{S}$ denotes projection onto $S$. It follows that minimization of the surrogate reduces to iteratively re-weighted least squares (IRWLS). When $y_i \in \{-1,1\}$, the surrogate becomes
\begin{eqnarray*}
L(\bbeta) & \le & \sum_{i=1}^m
\begin{cases} (y_i - \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k \le 1 \\
(\bx_i^t \bbeta_k - \bx_i^t \bbeta)^2 & y_i \bx_i^t \bbeta_k > 1 . \end{cases}
\end{eqnarray*}
If $\bX$ is the matrix with $i$th row $\bx_i^t$ and $\by$ is the vector with $i$th component $y_i$, then the surrogate can be expressed as
\begin{eqnarray*}
g_{\rho}(\bbeta \mid \bbeta_{k})
=
\left\|\begin{pmatrix}\bz_k \\\bp_{k} \end{pmatrix}-
\begin{pmatrix} \bX \\ \bD_{\rho}\end{pmatrix}\bbeta
\right\|^2,
\end{eqnarray*}
where $\bz_k$ has $i$th component $y_i$ when $y_i \bx_i^t\bbeta_k \le 1$
and $\bx_i^t\bbeta_k$ otherwise. 
This formulation of the problem connects two important cases.
A ridge penalty version requires setting $\bp_{k} = \bzero$ and $\bD_{\rho} = \begin{pmatrix} \sqrt{\rho} \bI_{p-1} & \bzero_{p-1} \\ \bzero_{p-1}^{t} & 0 \end{pmatrix}$ (Note: The redundant row is needed so that regularization is not applied to the intercept $\beta_{p}$).
For sparse estimation we set $\bp_k = \sqrt{\rho} P_{S_{c}}(\bbeta_k)$ and $\bD_{\rho} = \sqrt{\rho} \bI$.
The advantage of the latter is that it induces a target sparsity level $c$ directly via projection at the expense of convexity, whereas the former is a convex program but suffers from shrinkage.

Here we will focus on the sparse estimation problem based on projection and use the notation $g_{c,\rho}(\bbeta \mid \bbeta_{k})$ to emphasize hyperparameters.
Following the penalty method of optimization, our goal is to obtain $c$-sparse solutions by solving a sequence of subproblems.
Specifically, initialize $\rho_{0}$ and $\bbeta_{c,0}$.
We proceed as follows:
\begin{enumerate}
    \item Given $\rho_{l}$, obtain $\bbeta_{c,l+1} = \argmin_{\bbeta} L(\bbeta) + \rho_{l} \dist(\bbeta, S_{c})^{2}$ using the IRWLS surrogate and $\bbeta_{c,l}$ as a warm-start.
    \item Set $l \to l + 1$ and update $\rho_{l} \to \rho_{l+1}$.
\end{enumerate}
If the sequence $\{\rho_{l}\}$ is chosen appropriately, then $\bbeta_{c,l}$ converges to $\bbeta_{c}$ with negligible numerical instability.

\section*{\center Two Candidate MM Algorithms}
In this section we derive two algorithms using the IRWLS surrogate.

Naively, one may attempt to solve the normal equations directly and obtain an explicit update rule for $\bbeta_{k+1}$ based on the current iterate $\bbeta_{k}$.
The Hessian $\bX^{t} \bX + \rho \bI$ is likely to have poor numerical properties, especially in high dimensional problems, which thwart any line of attack based on iterative methods like LSMR.
Furthermore, one cannot rely on caching a factorization of the Hessian because it depends on a changing penalty coefficient $\rho$.

Alternatively, if $\bX$ has full singular value decomposition $\bU \bS \bV^{t}$ then the normal equations reduce to
\begin{equation}
\label{alg:MM}
\begin{aligned}
    (\bV \bS^{t} \bS \bV^{t} + \rho \bI) \bbeta &= \bX^{t} \bz_{k} + \rho \bp_{k} \\
    \implies \bbeta_{k+1} &= \bV \bD^{-1} \bS^{t} \bU^{t} \bz_{k}
    + \rho \bV \bD^{-1} \bV^{t} \bp_{k} \\
    \implies \bbeta_{k+1} &= \bM_{1} \bz_{k} + \bM_{2} \bp_{k}.
\end{aligned}
\end{equation}
where $\bD$ is diagonal with $d_{i} = s_{i}^{2} + \rho$.
The matrices $\bM_{1}$ and $\bM_{2}$ may be cached once $\rho$ is changed.
This makes for a simple MM algorithm based on two GEMV operations per iteration.
Alternatively, one can carry out matrix-vector products using only two additional buffers.
In either case, Nesterov acceleration is a prerequisite for a fast proximal distance algorithm.

The method of steepest descent is also attractive.
The gradient for the IRWLS surrogate is the sum $-\sum_{i=1}^m 1_{\{1-y_i\bx_i^t\bbeta > 0\}}(1-y_i\bx_i^t\bbeta)y_i\bx_i$.
Because the surrogate is a quadratic, it is easy to compute an approximately optimal step size $\gamma_{k}$ for a given descent direction $\bq_{k} \equiv \nabla g_{\rho}(\bbeta_{k} \mid \bbeta_{k})$.
The steepest descent update is therefore
\begin{equation}
\label{alg:SD}
\begin{aligned}
    \gamma_{k} &= \argmin_{\gamma} g_{\rho}(\bbeta_{k} - \gamma \bq_{k})
    = \frac{\|\bq_{k}\|^{2}}{\|\bX \bq_{k}\|^{2} + \rho \|\bq_{k}\|^{2}}, \\
    \bbeta_{k+1} &= \bbeta_{k} - \gamma_{k} \bq_{k}.
\end{aligned}
\end{equation}
In practice, the denominator in the step size formula should be perturbed by a small number $\epsilon$ (such as the machine epsilon) to avoid the indeterminate form $0 / 0$.
Furthermore, step-halving should be used to guarantee decreasing the penalized objective.

\section*{\center An Exact Optimal Value for MM Iterates}

Let us now consider the theoretical properties of the surrogate
\begin{equation}
    \label{eq:surrogate}
    g_{\rho}(\bbeta \mid \bbeta_{k})
    =
    \frac{1}{2} \left\|
        \begin{bmatrix}
            \bz_{k} \\ \sqrt{\rho} P_{S}(\bbeta_{k})
        \end{bmatrix}
        -
        \begin{bmatrix}
            \bX \\ \sqrt{\rho} \bI
        \end{bmatrix}
        \bbeta
    \right\|^{2}
\end{equation}
from the perspective of duality.
Although a sparsity set $S$ is not convex, our surrogate is convex in $\bbeta$ for fixed $\rho > 0$ and anchor point $\bbeta_{k}$ becauase its Hessian $\bX^{t}\bX + \rho \bI$ is positive definite.
Thus, let us pass to the strictly convex quadratic $f(\bx) = \frac{1}{2} \bx^{t} \bA \bx + \bb^{t} \bx + c$.
It is straightforward to derive its Fenchel conjugate $f^{\ast}(\by) = \frac{1}{2} (\by - \bb)^{t} \bA^{-1} (\by - \bb) - c$.
We may now consider the primal and dual programs
\[
    \text{primal:}~\min_{\bx} f(\bx)
    \qquad
    \text{dual:}~\max_{\by} -f^{\ast}(\by).
\]
Because $\bA \succ 0$ implies $\bA^{-1} \succ 0$, strong duality holds and so we note
\[
    f(\bx_{\mathrm{opt}}) = f^{\ast}(\by_{\mathrm{opt}}) = c,
\]
where $\bx_{\mathrm{opt}} = \bA^{-1} \bb$ and $\by_{\mathrm{opt}} = \bb$.

Translating back to minimization of the surrogate in Equation (\ref{eq:surrogate}), we set $\bA = \bX^{t} \bX + \rho \bI$, $\bb = -\bX^{t} \bz_{k} - \rho P_{S}(\bbeta_{k})$, and $c = \frac{1}{2}[\|\bz_{k}\|^{2} + \rho \|P_{S}(\bbeta_{k})\|^{2}]$.
Given that $\bbeta_{k+1} = \argmin_{\bbeta} g(\bbeta \mid \bbeta_{k})$, we have shown that
\[
    g_{\rho}(\bbeta_{k+1} \mid \bbeta_{k})
    =
    \frac{1}{2}[\|\bz_{k}\|^{2} + \rho \|P_{S}(\bbeta_{k})\|^{2}],
\]
which avoids matrix-vector muliplication in checking objectives after iterating via algorithm (\ref{alg:MM}) or (\ref{alg:SD}).
Further, it establishes an optimality criterion for the steepest descent algorithm (\ref{alg:SD}).


\section*{\center Non-linear Decison Boundaries}
Now we attempt the so-called ``kernel trick'' to extend our MM algorithms for linear SVM classifiers to non-linear decision boundaries.
Given a non-linear mapping $\phi(\bx)$ into a possibly infinite dimensional space on feature vectors, the Riesz representation theorem guarantees that one can recover a signal $\bbeta$ via the linear combination $\bbeta = \sum_{i} y_{i} \alpha_{i} \phi(\bx_{i})$. We therefore replace the hinge loss on $\bbeta$ with
\[
    L(\balpha) = \sum_{i} \max\{0, 1-y_{i} \sum_{j} y_{j} \alpha_{j} \langle \phi(\bx_{i}), \phi(\bx_{j})\rangle\}^{2}.
\]
Majorizing the hinge loss and applying a distance penalty on the $\balpha \in \mathbb{R}^{n}$ leads to the quadratic surrogate
\begin{equation}
    \label{eq:nlsurrogate}
    g_{\rho}(\balpha \mid \balpha_{k})
    =
    \frac{1}{2} \left\|
    \begin{pmatrix}
        \bz_{k} \\ \sqrt{\rho} P_{S}(\balpha_{k})
    \end{pmatrix}
    -
    \begin{pmatrix}
        \bK \bY \\ \sqrt{\rho} \bI
    \end{pmatrix}
    \balpha
    \right\|^{2},
\end{equation}
where $K_{ij} = \langle \phi(\bx_{i}), \phi(\bx_{j}) \rangle$ is a positive semi-definite kernel and we define $\bY = \mathrm{Diag}(\by)$.
Vector $\bz_{k}$ is defined in an analogous fashion as in (\ref{eq:surrogate})
\[
    z_{k,i} = \begin{cases}
        y_{i}, & y_{i} \sum_{j} y_{j} \alpha_{k,j} \langle \phi(\bx_{i}), \phi(\bx_{j})\rangle \le 1 \\
        \sum_{j} y_{j} \alpha_{k,j} \langle \phi(\bx_{i}), \phi(\bx_{j})\rangle, & \text{otherwise}.
    \end{cases}
\]
In this version of the problem, one projects model parameters $\balpha$ onto a sparsity set $S$ to identify samples that drive a decision boundary.

The MM algorithm analogous to algorithm (\ref{alg:MM}) is
\begin{equation}
    \label{alg:nlMM}
    \balpha_{k+1}
    =
    \bY \bQ \bD_{1} \bQ^{t} \bz_{k} + \rho \bY \bQ \bD_{2} \bQ^{t} \bY P_{S}(\balpha_{k}),
\end{equation}
where matrix $\bK$ has spectral decomposition $\bQ \bLambda \bQ^{t}$, $\bD_{1} = (\Lambda^{2} + \rho \bI)^{-1} \bLambda$, and $\bD_{2} = (\Lambda^{2} + \rho \bI)^{-1}$.
This derivation exploits the fact that $\bY \bY = \bI$ and $\bQ^{t} \bQ = \bQ \bQ^{t} = \bI$.
As before, a single decomposition allows one to anneal $\rho$ and tune the choice of sparsity set $S$.
The required matrix inverses involve positive definite diagonal matrices which are trivial to compute.

Similarly, the steepest descent algorithm to minimize surrogate (\ref{eq:nlsurrogate}) is
\begin{equation}
\label{alg:nlSD}
\begin{aligned}
    \gamma_{k} &= \argmin_{\gamma} g_{\rho}(\balpha_{k} - \gamma \bq_{k})
    = \frac{\|\bq_{k}\|^{2}}{\|\bK \bY \bq_{k}\|^{2} + \rho \|\bq_{k}\|^{2}}, \\
    \balpha_{k+1} &= \balpha_{k} - \gamma_{k} \bq_{k}.
\end{aligned}
\end{equation}

\section*{\center Numerical Experiments}

Here we apply our MM algorithms to classification tasks on both synthetic and ``real world'' data.
The chosen data sets are as follows:
\begin{table}[!h]
    \centering
    \begin{tabular}{lllll}
        \toprule
        Name & Classes & No. Train & Features & No. Test \\
        \midrule
        \texttt{synthetic} & 2 & 1000 & 500 & 1000 \\
        \texttt{iris} & 3 & 120 & 4 & 30 \\
        \texttt{letter-recognition} & 26 & 16000 & 16 & 4000 \\
        \texttt{MNIST-digits} & 10 & 60000 & 784 & 10000 \\
        \bottomrule
    \end{tabular}
    \caption{Summary of data sets for experiments.}
\end{table}
Binary classification is straightforward using the decision rule $\bx \mapsto \sgn (\bx^t \bbeta$).
In the examples with multiple classes $N$, we train $\binom{N}{2}$ SVMs under the one-against-one paradigm.
If classes are labeled $\{1, 2, \ldots, N\}$ then the we take our decision rule to be the ``Max Vote'' classifier $\bx \mapsto \arg\max v_{j}(\bx)$ where $v_{j}(\bx)$ is the number of votes received for class $j$ from each of the $\binom{N}{2}$ SVMs based on the binary decision rule.

Here we refer to the algorithms implied by (\ref{alg:MM}) and (\ref{alg:SD}) as ``MM'' and ``SD'', respectively.
Method MM uses Nesterov acceleration, whereas SD only uses step-halving to avoid an increase in the objective.

\subsection*{Experiment 1: Sensitivity to Initial Conditions}

To check sensitivity to the initial guess, $\bbeta_{0}$, we solve each SVM problem with 100 replicates with each component of $\bbeta_{0}$ drawn from the standard normal distribution.
We report the total number of iterations, time, test accuracy, objective, and distance to the sparsity set for each dataset in Table \ref{tab:experiment1}.
Iteration counts, timings, objectives, and distances are summed over multiple SVMs in the case of multiple classes; for example, in an example with 10 classes we take the objective as $\sum_{j} \text{objective}(\text{SVM}~j)$ where the sum ranges over $\binom{10}{2}$ SVMs.
Values for objectives and distances are adjusted by number of samples and number of features, respectively, to account for problem size.
During training, each SVM (in both binary and multi-class cases) is alloted $10^{4}$ inner iterations to minimize the distance penalized objective for fixed $\rho$ up to a relative tolerance $\epsilon = 10^{-6}$.
The sparsity level is restricted to $c = \lceil 0.5 \times \text{features} \rceil$ across all examples.
We set $\rho_{0} = 1$ and send $\rho_{n}$ to $\infty$ by the update $\rho_{n+1} = 1.5 \rho_{n}$ over 50 outer iterations.
\begin{table}[!h]
    \centering
    \begin{scriptsize}
    \begin{tabular}{llllll}
        \toprule
        Name & Iter. & Time (s) & Acc. (\%) & Obj. & Dist. \\
        \midrule
        \texttt{synthetic} &&&&& \\
        \hphantom{ab} MM & 269 & 0.34 & 87.0 & $2.273 \times 10^{-7}$ & $1.4 \times 10^{-6}$ \\
        \hphantom{ab} SD & 4511 & 0.26 & 100.0 & $1.202 \times 10^{-6}$ & $5.3 \times 10^{-6}$ \\
        \texttt{iris} &&&&& \\
        \hphantom{ab} MM & 2440 & $2.0 \times 10^{-3}$ & 90.0 & 0.1990 & $3.7 \times 10^{-4}$ \\
        \hphantom{ab} SD & 7527 & $7.6 \times 10^{-3}$ & 90.0 & 0.2715 & $6.2 \times 10^{-4}$ \\
        \texttt{letter-recognition} &&&&& \\
        \hphantom{ab} MM & $1.5 \times 10^{6}$ & 10 & 78.0 & 67.07 & 1.0 \\
        \hphantom{ab} SD & $4.8 \times 10^{6}$ & 58 & 73.0 & 109.4 & 1.3 \\
        \texttt{MNIST-digits} &&&&& \\
        \hphantom{ab} MM & 8049 & 351 & 10.0 & 42.46 & 0.040 \\
        \hphantom{ab} SD & $1.4 \times 10^{5}$ & 898 & 11.0 & 42.48 & 0.042 \\
        \bottomrule
    \end{tabular}
    \end{scriptsize}
    \caption{
        \label{tab:experiment1}
        Results indicate median values aggregated from 100 replicates.
        }
\end{table}

\subsection*{Experiment 2: Sensitivity to Sparsity Level}

Next we examine sensitivity of various metrics to the choice of sparsity sets, including the (i) mean squared error of model parameters $\bbeta$ to the ground truth $\bbeta^{0}$, (ii) estimates for the bias parameter, (iii) Type I and Type II errors, (iv) prediction accuracy, and (v) compute time.
Because some metrics require knowledge of $\bbeta^{0}$, we simulate a synthetic data set:
\begin{enumerate}
    \item Inputs: $n$ samples, $p$ features, $s$ number of causal features.
    \item For each row $\bx_{i}$ of the data matrix $\bX$ (without the column $\boldsymbol{1}$), take $x_{ji} = \pm j/p + \mathcal{N}(0,1)$. This choice sets different scales for each feature in order to avoid exchangeability issues that may affect uniqueness of $\bbeta^{0}$.
    \item Standardize $\bX$ so that features have mean $0$ and variance $1$.
    \item Simulate a random set of indices $\mathcal{J} \subset \{1,2,\ldots,p\}$ such that $|\mathcal{J}| = s$.
    \item Construct $\bbeta^{0} \in \mathbb{R}^{p+1}$ such that $\beta_{j}^{0} = j/p + \mathcal{N}(0,1)$ if $j \in \mathcal{J}$; otherwise $\beta_{j}^{0} = 0$. Note that the bias parameter $\beta_{p+1}^{0} = 0$.
    \item Take $\by = \sgn([\bX~\boldsymbol{1}] \bbeta^{0})$.
\end{enumerate}
We use this recipe to construct 3 examples each with $n = 1000$ samples and $p = 500$ features: \texttt{signal-dense} ($s=500$), \texttt{signal-sparse} ($s=50$), and \texttt{signal-vsparse} ($s=5$).
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{signal-dense}
    \caption{
        Results with $s = 500$ (purple).
        SD is green, MM is in blue.
    }
\end{figure}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{signal-sparse}
    \caption{
        Results with $s = 50$ (purple).
        SD is green, MM is in blue.
    }
\end{figure}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{signal-vsparse}
    \caption{
        Results with $s = 5$ (purple).
        SD is green, MM is in blue.
    }
\end{figure}

\end{document}
